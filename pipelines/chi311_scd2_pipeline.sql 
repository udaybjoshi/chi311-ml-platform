-- =============================================================================
-- Chicago 311 Intelligence Platform - Lakeflow Pipeline with SCD Type 2
-- =============================================================================
-- 
-- Architecture:
--   Bronze (Streaming) → Silver (SCD2 History) → Gold (Aggregates + ML Features)
--
-- Key Pattern: Uses DLT's APPLY CHANGES INTO for SCD Type 2 tracking
-- This preserves full history of status changes for 311 requests
--
-- Chicago 311 API: https://data.cityofchicago.org/resource/v6vf-nfxy.json
--
-- Key Findings from Exploration (00_setup_exploration.py):
--   - Status values: Open, Completed, Canceled (note: one 'l')
--   - Info calls: 40% of volume ("311 INFORMATION ONLY CALL")
--   - Daily service requests: ~3,000 (excluding info calls)
--   - Anomaly threshold: 4,851 (mean + 2σ)
--   - Weekend drop: 35-40%
--   - Ward 28: 39% of requests (info call administrative ward)
--
-- To run this pipeline:
-- 1. Go to Workflows > Lakeflow Declarative Pipelines
-- 2. Create new pipeline
-- 3. Point to this file
-- 4. Configure: Serverless, Development mode
-- =============================================================================


-- =============================================================================
-- BRONZE LAYER: Raw Data Landing Zone
-- =============================================================================
-- Purpose: Capture raw data from Chicago Data Portal API with minimal transformation
-- Pattern: Streaming (append-only)
-- =============================================================================

CREATE STREAMING TABLE bronze_raw_311_requests
COMMENT "Raw 311 service requests from Chicago Data Portal API - landing zone"
TBLPROPERTIES (
    "quality" = "bronze",
    "pipelines.autoOptimize.managed" = "true"
)
AS SELECT
    -- Business key
    sr_number,
    
    -- Timestamps
    created_date,
    closed_date,
    last_modified_date,
    
    -- Request classification
    sr_type,
    sr_short_code,
    owner_department,
    
    -- Status (tracked for SCD2)
    status,
    
    -- Location fields
    ward,
    community_area,
    street_address,
    city,
    state,
    zip_code,
    latitude,
    longitude,
    location,
    
    -- Channel/Source
    origin,
    
    -- Flags
    duplicate,
    legacy_record,
    
    -- Metadata
    current_timestamp() AS _ingestion_timestamp,
    input_file_name() AS _source_file
FROM STREAM read_files(
    '/Volumes/main/chi311/raw_data/',
    format => 'json',
    header => true,
    inferSchema => true
);


-- =============================================================================
-- BRONZE STAGING: Cleaned staging table for CDC processing
-- =============================================================================
-- Purpose: Clean and prepare data for SCD2 processing
-- This is the source for APPLY CHANGES INTO
-- 
-- Data Quality Thresholds (from 00_setup_exploration.py):
--   - sr_number: 0% null (critical)
--   - created_date: 0% null (critical)
--   - sr_type: 0% null (critical)
--   - status: 0% null (critical)
--   - ward: 0.2% null (mostly=0.99)
--   - coordinates: 0.2% null (mostly=0.99)
-- =============================================================================

CREATE STREAMING TABLE bronze_staged_311_requests (
    CONSTRAINT valid_sr_number EXPECT (sr_number IS NOT NULL) ON VIOLATION DROP ROW,
    CONSTRAINT valid_created_date EXPECT (created_date IS NOT NULL) ON VIOLATION DROP ROW,
    CONSTRAINT valid_sr_type EXPECT (sr_type IS NOT NULL) ON VIOLATION DROP ROW,
    CONSTRAINT valid_status EXPECT (status IS NOT NULL) ON VIOLATION DROP ROW,
    CONSTRAINT valid_status_values EXPECT (status IN ('Open', 'Completed', 'Canceled')) ON VIOLATION DROP ROW
)
COMMENT "Staged 311 requests ready for SCD2 processing - cleaned and validated"
TBLPROPERTIES ("quality" = "bronze")
AS SELECT
    -- Business key
    sr_number,
    
    -- Sequence column for ordering changes
    -- Priority: last_modified > closed > created > ingestion
    COALESCE(
        TO_TIMESTAMP(last_modified_date),
        TO_TIMESTAMP(closed_date),
        TO_TIMESTAMP(created_date),
        _ingestion_timestamp
    ) AS _sequence_timestamp,
    
    -- Timestamps (cleaned)
    TO_TIMESTAMP(created_date) AS created_date,
    TO_TIMESTAMP(closed_date) AS closed_date,
    TO_TIMESTAMP(last_modified_date) AS last_modified_date,
    
    -- Request classification (standardized)
    TRIM(sr_type) AS sr_type,
    TRIM(sr_short_code) AS sr_short_code,
    TRIM(owner_department) AS owner_department,
    
    -- Status (standardized to uppercase for consistency)
    UPPER(TRIM(status)) AS status,
    
    -- Location info
    CAST(ward AS INT) AS ward,
    TRIM(community_area) AS community_area,
    TRIM(street_address) AS street_address,
    TRIM(zip_code) AS zip_code,
    
    -- Coordinates (validated - Chicago bounding box)
    -- Chicago bounds: lat 41.6-42.1, lon -87.95 to -87.5
    CASE 
        WHEN CAST(latitude AS DOUBLE) BETWEEN 41.6 AND 42.1 
         AND CAST(longitude AS DOUBLE) BETWEEN -87.95 AND -87.5 
        THEN CAST(latitude AS DOUBLE)
        ELSE NULL 
    END AS latitude,
    CASE 
        WHEN CAST(latitude AS DOUBLE) BETWEEN 41.6 AND 42.1 
         AND CAST(longitude AS DOUBLE) BETWEEN -87.95 AND -87.5 
        THEN CAST(longitude AS DOUBLE)
        ELSE NULL 
    END AS longitude,
    
    -- Channel info (standardized)
    UPPER(TRIM(origin)) AS origin,
    
    -- Flags
    CAST(duplicate AS BOOLEAN) AS is_duplicate,
    CAST(legacy_record AS BOOLEAN) AS is_legacy,
    
    -- Derived: Is this an informational call? (40% of volume)
    CASE 
        WHEN TRIM(sr_type) = '311 INFORMATION ONLY CALL' THEN TRUE 
        ELSE FALSE 
    END AS is_info_call,
    
    -- Metadata
    _ingestion_timestamp,
    _source_file
    
FROM STREAM(LIVE.bronze_raw_311_requests);


-- =============================================================================
-- SILVER LAYER: SCD Type 2 History Table
-- =============================================================================
-- Purpose: Maintain full history of 311 request changes
-- Pattern: SCD Type 2 via APPLY CHANGES INTO
-- 
-- SCD2 Columns (auto-managed by DLT):
--   __START_AT: When this version became effective (valid_from)
--   __END_AT: When this version was superseded (valid_to), NULL = current
--
-- Note: Chicago 311 has simpler status model (Open → Completed/Canceled)
-- Expected avg versions per request: 1.2-1.5 (82% close instantly)
-- =============================================================================

-- Target table for SCD2 tracking
CREATE STREAMING TABLE silver_scd2_311_requests
COMMENT "SCD Type 2 history of 311 service requests - tracks all status changes"
TBLPROPERTIES (
    "quality" = "silver",
    "pipelines.autoOptimize.managed" = "true"
);

-- Apply CDC changes with SCD Type 2
APPLY CHANGES INTO LIVE.silver_scd2_311_requests
FROM STREAM(LIVE.bronze_staged_311_requests)
KEYS (sr_number)
SEQUENCE BY _sequence_timestamp
COLUMNS * EXCEPT (_ingestion_timestamp, _source_file, _sequence_timestamp)
STORED AS SCD TYPE 2;


-- =============================================================================
-- SILVER LAYER: Current State View
-- =============================================================================
-- Purpose: Convenience view for current record state
-- Filters SCD2 table for only active records (__END_AT IS NULL)
-- =============================================================================

CREATE LIVE VIEW silver_current_311_requests
COMMENT "Current state of 311 requests (latest version only)"
AS SELECT
    sr_number,
    created_date,
    closed_date,
    last_modified_date,
    sr_type,
    sr_short_code,
    owner_department,
    status,
    ward,
    community_area,
    street_address,
    zip_code,
    latitude,
    longitude,
    origin,
    is_duplicate,
    is_legacy,
    is_info_call,
    
    -- Derived: resolution time in hours
    CASE 
        WHEN closed_date IS NOT NULL 
        THEN TIMESTAMPDIFF(HOUR, created_date, closed_date)
        ELSE NULL 
    END AS resolution_hours,
    
    -- SCD2 metadata exposed
    __START_AT AS valid_from,
    __END_AT AS valid_to,
    
    -- Processing timestamp
    current_timestamp() AS _view_timestamp
    
FROM LIVE.silver_scd2_311_requests
WHERE __END_AT IS NULL;  -- Current records only


-- =============================================================================
-- SILVER LAYER: Status History View
-- =============================================================================
-- Purpose: Expose full history for analytics
-- Useful for time-in-status analysis
-- =============================================================================

CREATE LIVE VIEW silver_status_history
COMMENT "Full status change history for 311 requests"
AS SELECT
    sr_number,
    created_date,
    status,
    sr_type,
    ward,
    is_info_call,
    
    -- SCD2 version timestamps
    __START_AT AS version_start,
    __END_AT AS version_end,
    
    -- Time in this status (hours)
    CASE 
        WHEN __END_AT IS NOT NULL 
        THEN TIMESTAMPDIFF(HOUR, __START_AT, __END_AT)
        ELSE TIMESTAMPDIFF(HOUR, __START_AT, current_timestamp())
    END AS hours_in_status,
    
    -- Version sequencing
    ROW_NUMBER() OVER (PARTITION BY sr_number ORDER BY __START_AT) AS version_number,
    
    -- Is this the current version?
    CASE WHEN __END_AT IS NULL THEN TRUE ELSE FALSE END AS is_current
    
FROM LIVE.silver_scd2_311_requests;


-- =============================================================================
-- GOLD LAYER: Aggregated Tables for Analytics & ML
-- =============================================================================
-- Purpose: Pre-aggregated tables for dashboards and ML model features
-- Pattern: Materialized aggregations with feature engineering
-- =============================================================================

-- -----------------------------------------------------------------------------
-- Gold Table 1: Daily Aggregates by Ward and SR Type
-- -----------------------------------------------------------------------------
CREATE LIVE TABLE gold_daily_aggregates
COMMENT "Daily aggregates by ward and service request type"
TBLPROPERTIES (
    "quality" = "gold",
    "pipelines.autoOptimize.managed" = "true"
)
AS SELECT
    DATE(created_date) AS date,
    ward,
    sr_type,
    is_info_call,
    
    -- Volume metrics
    COUNT(*) AS total_requests,
    SUM(CASE WHEN status = 'COMPLETED' THEN 1 ELSE 0 END) AS completed_count,
    SUM(CASE WHEN status = 'OPEN' THEN 1 ELSE 0 END) AS open_count,
    SUM(CASE WHEN status = 'CANCELED' THEN 1 ELSE 0 END) AS canceled_count,
    
    -- Resolution metrics
    AVG(resolution_hours) AS avg_resolution_hours,
    PERCENTILE_APPROX(resolution_hours, 0.5) AS median_resolution_hours,
    
    -- Completion rate
    SUM(CASE WHEN status = 'COMPLETED' THEN 1.0 ELSE 0.0 END) / COUNT(*) AS completion_rate,
    
    -- Channel breakdown
    SUM(CASE WHEN origin = 'PHONE' THEN 1 ELSE 0 END) AS phone_requests,
    SUM(CASE WHEN origin = 'WEB' THEN 1 ELSE 0 END) AS web_requests,
    SUM(CASE WHEN origin = 'APP' THEN 1 ELSE 0 END) AS app_requests,
    
    -- Temporal features (for ML)
    DAYOFWEEK(DATE(created_date)) AS day_of_week,
    MONTH(DATE(created_date)) AS month,
    CASE WHEN DAYOFWEEK(DATE(created_date)) IN (1, 7) THEN 1 ELSE 0 END AS is_weekend,
    
    -- Metadata
    current_timestamp() AS _processed_at
    
FROM LIVE.silver_current_311_requests
GROUP BY 
    DATE(created_date),
    ward,
    sr_type,
    is_info_call;


-- -----------------------------------------------------------------------------
-- Gold Table 2: Ward Daily Summary (with lag features)
-- -----------------------------------------------------------------------------
CREATE LIVE TABLE gold_ward_daily_summary
COMMENT "Ward-level daily summary with lag features for forecasting"
TBLPROPERTIES (
    "quality" = "gold",
    "pipelines.autoOptimize.managed" = "true"
)
AS 
WITH daily_counts AS (
    SELECT
        DATE(created_date) AS date,
        ward,
        COUNT(*) AS total_requests,
        -- Service requests only (excluding info calls)
        SUM(CASE WHEN is_info_call = FALSE THEN 1 ELSE 0 END) AS service_requests,
        SUM(CASE WHEN is_info_call = TRUE THEN 1 ELSE 0 END) AS info_calls,
        COUNT(DISTINCT sr_type) AS unique_sr_types,
        AVG(resolution_hours) AS avg_resolution_hours,
        SUM(CASE WHEN status = 'COMPLETED' THEN 1.0 ELSE 0.0 END) / COUNT(*) AS completion_rate
    FROM LIVE.silver_current_311_requests
    GROUP BY DATE(created_date), ward
)
SELECT
    date,
    ward,
    total_requests,
    service_requests,
    info_calls,
    unique_sr_types,
    avg_resolution_hours,
    completion_rate,
    
    -- Lag features (shifted to prevent leakage)
    LAG(total_requests, 1) OVER (PARTITION BY ward ORDER BY date) AS requests_1d_ago,
    LAG(total_requests, 7) OVER (PARTITION BY ward ORDER BY date) AS requests_7d_ago,
    LAG(total_requests, 28) OVER (PARTITION BY ward ORDER BY date) AS requests_28d_ago,
    
    -- Rolling averages (using LAG to prevent leakage)
    AVG(total_requests) OVER (
        PARTITION BY ward 
        ORDER BY date 
        ROWS BETWEEN 8 PRECEDING AND 1 PRECEDING
    ) AS rolling_7d_avg,
    
    AVG(total_requests) OVER (
        PARTITION BY ward 
        ORDER BY date 
        ROWS BETWEEN 29 PRECEDING AND 1 PRECEDING
    ) AS rolling_28d_avg,
    
    -- Temporal features
    DAYOFWEEK(date) AS day_of_week,
    MONTH(date) AS month,
    CASE WHEN DAYOFWEEK(date) IN (1, 7) THEN 1 ELSE 0 END AS is_weekend,
    
    -- Metadata
    current_timestamp() AS _processed_at
    
FROM daily_counts;


-- -----------------------------------------------------------------------------
-- Gold Table 3: Citywide Daily Summary (Primary forecasting table)
-- -----------------------------------------------------------------------------
-- This is the main input table for Prophet forecasting
-- Includes both ALL requests and SERVICE-ONLY requests
-- 
-- Baseline from exploration:
--   All requests: mean=5,000, std=1,290, anomaly_threshold=7,580
--   Service only: mean=3,001, std=925, anomaly_threshold=4,851
-- -----------------------------------------------------------------------------
CREATE LIVE TABLE gold_citywide_daily_summary
COMMENT "Citywide daily summary - primary table for Prophet forecasting"
TBLPROPERTIES (
    "quality" = "gold",
    "pipelines.autoOptimize.managed" = "true"
)
AS 
WITH daily_totals AS (
    SELECT
        DATE(created_date) AS date,
        COUNT(*) AS total_requests,
        -- Service requests only (for forecasting)
        SUM(CASE WHEN is_info_call = FALSE THEN 1 ELSE 0 END) AS service_requests,
        SUM(CASE WHEN is_info_call = TRUE THEN 1 ELSE 0 END) AS info_calls,
        COUNT(DISTINCT sr_type) AS unique_sr_types,
        COUNT(DISTINCT ward) AS wards_with_requests,
        AVG(resolution_hours) AS avg_resolution_hours,
        -- Exclude instant closures for meaningful resolution time
        AVG(CASE WHEN resolution_hours > 0.1 THEN resolution_hours END) AS avg_resolution_hours_excl_instant,
        SUM(CASE WHEN status = 'COMPLETED' THEN 1.0 ELSE 0.0 END) / COUNT(*) AS completion_rate
    FROM LIVE.silver_current_311_requests
    GROUP BY DATE(created_date)
)
SELECT
    -- Prophet requires 'ds' and 'y' columns
    date AS ds,
    service_requests AS y,  -- Use service requests for forecasting (excludes info calls)
    
    -- Additional metrics
    date,
    total_requests,
    service_requests,
    info_calls,
    unique_sr_types,
    wards_with_requests,
    avg_resolution_hours,
    avg_resolution_hours_excl_instant,
    completion_rate,
    
    -- Lag features
    LAG(service_requests, 1) OVER (ORDER BY date) AS requests_1d_ago,
    LAG(service_requests, 7) OVER (ORDER BY date) AS requests_7d_ago,
    LAG(service_requests, 28) OVER (ORDER BY date) AS requests_28d_ago,
    LAG(service_requests, 365) OVER (ORDER BY date) AS requests_1y_ago,
    
    -- Rolling averages (service requests)
    AVG(service_requests) OVER (ORDER BY date ROWS BETWEEN 8 PRECEDING AND 1 PRECEDING) AS rolling_7d_avg,
    AVG(service_requests) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND 1 PRECEDING) AS rolling_28d_avg,
    
    -- Year-over-year change
    CASE 
        WHEN LAG(service_requests, 365) OVER (ORDER BY date) > 0
        THEN (service_requests - LAG(service_requests, 365) OVER (ORDER BY date)) * 1.0 
             / LAG(service_requests, 365) OVER (ORDER BY date)
        ELSE NULL
    END AS yoy_change,
    
    -- Temporal features
    DAYOFWEEK(date) AS day_of_week,
    MONTH(date) AS month,
    DAYOFYEAR(date) AS day_of_year,
    WEEKOFYEAR(date) AS week_of_year,
    CASE WHEN DAYOFWEEK(date) IN (1, 7) THEN 1 ELSE 0 END AS is_weekend,
    
    -- Anomaly flags (based on exploration thresholds)
    -- Service requests anomaly: > 4,851 (mean + 2σ)
    CASE WHEN service_requests > 4851 THEN TRUE ELSE FALSE END AS is_anomaly_service,
    -- All requests anomaly: > 7,580 (mean + 2σ)
    CASE WHEN total_requests > 7580 THEN TRUE ELSE FALSE END AS is_anomaly_total,
    
    -- Metadata
    current_timestamp() AS _processed_at
    
FROM daily_totals;


-- -----------------------------------------------------------------------------
-- Gold Table 4: Status Transition Analysis (Leverages SCD2 history)
-- -----------------------------------------------------------------------------
-- Note: Chicago 311 has simple transitions:
--   Open → Completed (most common, 83.7%)
--   Open → Canceled (rare, 1%)
-- -----------------------------------------------------------------------------
CREATE LIVE TABLE gold_status_transitions
COMMENT "Status transition patterns - uses SCD2 history for time-in-status analytics"
TBLPROPERTIES (
    "quality" = "gold",
    "pipelines.autoOptimize.managed" = "true"
)
AS 
WITH status_versions AS (
    SELECT
        sr_number,
        status,
        sr_type,
        is_info_call,
        version_start,
        version_end,
        hours_in_status,
        version_number,
        LEAD(status) OVER (PARTITION BY sr_number ORDER BY version_start) AS next_status
    FROM LIVE.silver_status_history
)
SELECT
    status AS from_status,
    next_status AS to_status,
    is_info_call,
    COUNT(*) AS transition_count,
    AVG(hours_in_status) AS avg_hours_before_transition,
    PERCENTILE_APPROX(hours_in_status, 0.5) AS median_hours_before_transition,
    -- Exclude instant closures for meaningful time
    AVG(CASE WHEN hours_in_status > 0.1 THEN hours_in_status END) AS avg_hours_excl_instant,
    MIN(hours_in_status) AS min_hours,
    MAX(hours_in_status) AS max_hours,
    current_timestamp() AS _processed_at
FROM status_versions
WHERE next_status IS NOT NULL  -- Exclude current (no transition yet)
GROUP BY status, next_status, is_info_call;


-- -----------------------------------------------------------------------------
-- Gold Table 5: Department Performance Metrics
-- -----------------------------------------------------------------------------
CREATE LIVE TABLE gold_department_performance
COMMENT "Department-level performance metrics"
TBLPROPERTIES (
    "quality" = "gold",
    "pipelines.autoOptimize.managed" = "true"
)
AS SELECT
    owner_department,
    DATE(created_date) AS date,
    
    -- Volume
    COUNT(*) AS total_requests,
    SUM(CASE WHEN is_info_call = FALSE THEN 1 ELSE 0 END) AS service_requests,
    COUNT(DISTINCT sr_type) AS sr_types_handled,
    
    -- Resolution performance
    SUM(CASE WHEN status = 'COMPLETED' THEN 1 ELSE 0 END) AS completed_count,
    SUM(CASE WHEN status = 'COMPLETED' THEN 1.0 ELSE 0.0 END) / COUNT(*) AS completion_rate,
    AVG(resolution_hours) AS avg_resolution_hours,
    PERCENTILE_APPROX(resolution_hours, 0.5) AS median_resolution_hours,
    PERCENTILE_APPROX(resolution_hours, 0.9) AS p90_resolution_hours,
    
    -- Metadata
    current_timestamp() AS _processed_at
    
FROM LIVE.silver_current_311_requests
GROUP BY owner_department, DATE(created_date);


-- -----------------------------------------------------------------------------
-- Gold Table 6: SR Type Analysis (Top Request Types)
-- -----------------------------------------------------------------------------
CREATE LIVE TABLE gold_sr_type_summary
COMMENT "Service request type daily summary"
TBLPROPERTIES (
    "quality" = "gold",
    "pipelines.autoOptimize.managed" = "true"
)
AS SELECT
    DATE(created_date) AS date,
    sr_type,
    is_info_call,
    
    COUNT(*) AS total_requests,
    SUM(CASE WHEN status = 'COMPLETED' THEN 1 ELSE 0 END) AS completed_count,
    SUM(CASE WHEN status = 'COMPLETED' THEN 1.0 ELSE 0.0 END) / COUNT(*) AS completion_rate,
    AVG(resolution_hours) AS avg_resolution_hours,
    
    -- Top wards for this SR type
    MODE(ward) AS most_common_ward,
    COUNT(DISTINCT ward) AS wards_affected,
    
    current_timestamp() AS _processed_at
    
FROM LIVE.silver_current_311_requests
GROUP BY DATE(created_date), sr_type, is_info_call;


-- =============================================================================
-- DATA QUALITY MONITORING VIEWS
-- =============================================================================

-- Monitor SCD2 versioning health
CREATE LIVE VIEW dq_scd2_version_stats
COMMENT "Data quality: SCD2 versioning statistics"
AS SELECT
    COUNT(DISTINCT sr_number) AS total_unique_requests,
    COUNT(*) AS total_versions,
    ROUND(COUNT(*) * 1.0 / COUNT(DISTINCT sr_number), 2) AS avg_versions_per_request,
    SUM(CASE WHEN __END_AT IS NULL THEN 1 ELSE 0 END) AS current_versions,
    SUM(CASE WHEN __END_AT IS NOT NULL THEN 1 ELSE 0 END) AS historical_versions,
    MAX(__START_AT) AS latest_version_start,
    -- Expected: 1.2-1.5 versions per request (most close instantly)
    CASE 
        WHEN ROUND(COUNT(*) * 1.0 / COUNT(DISTINCT sr_number), 2) BETWEEN 1.0 AND 2.0 
        THEN 'HEALTHY'
        ELSE 'INVESTIGATE'
    END AS version_rate_status
FROM LIVE.silver_scd2_311_requests;


-- Monitor pipeline freshness
CREATE LIVE VIEW dq_pipeline_freshness
COMMENT "Data quality: Pipeline freshness monitoring"
AS SELECT
    'bronze_raw' AS layer,
    MAX(_ingestion_timestamp) AS latest_record,
    COUNT(*) AS total_records,
    TIMESTAMPDIFF(HOUR, MAX(_ingestion_timestamp), current_timestamp()) AS hours_since_update
FROM LIVE.bronze_raw_311_requests
UNION ALL
SELECT
    'silver_scd2' AS layer,
    MAX(__START_AT) AS latest_record,
    COUNT(*) AS total_records,
    TIMESTAMPDIFF(HOUR, MAX(__START_AT), current_timestamp()) AS hours_since_update
FROM LIVE.silver_scd2_311_requests;


-- Monitor info call ratio (should be ~40%)
CREATE LIVE VIEW dq_info_call_ratio
COMMENT "Data quality: Info call ratio monitoring"
AS SELECT
    DATE(created_date) AS date,
    COUNT(*) AS total_requests,
    SUM(CASE WHEN is_info_call = TRUE THEN 1 ELSE 0 END) AS info_calls,
    ROUND(SUM(CASE WHEN is_info_call = TRUE THEN 1.0 ELSE 0.0 END) / COUNT(*) * 100, 1) AS info_call_pct,
    -- Expected: 35-45%
    CASE 
        WHEN SUM(CASE WHEN is_info_call = TRUE THEN 1.0 ELSE 0.0 END) / COUNT(*) BETWEEN 0.35 AND 0.45 
        THEN 'NORMAL'
        ELSE 'INVESTIGATE'
    END AS ratio_status
FROM LIVE.silver_current_311_requests
GROUP BY DATE(created_date)
ORDER BY date DESC
LIMIT 30;


-- Monitor status distribution
CREATE LIVE VIEW dq_status_distribution
COMMENT "Data quality: Status value distribution"
AS SELECT
    status,
    COUNT(*) AS count,
    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1) AS pct
FROM LIVE.silver_current_311_requests
GROUP BY status
ORDER BY count DESC;